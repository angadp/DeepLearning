{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats vs Dogs - Achieving more with less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to distinguish between cats and dogs with close to 90% accuracy. The goal here is to create my own neural network and no overdo it with Inception V2 or somthing like that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data with augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8005 images belonging to 2 classes.\n",
      "Found 2023 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    zoom_range=0.15,\n",
    "    fill_mode='nearest',\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    rotation_range=3\n",
    ")\n",
    "test_data = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "#     fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_data.flow_from_directory('./data/training_set/training_set', target_size=(230, 230), batch_size=32, class_mode='binary')\n",
    "test_generator = test_data.flow_from_directory('./data/test_set/test_set', target_size=(230, 230), batch_size=32, class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(256, (11,11), strides=(2,2), input_shape=(230,230, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (5,5)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, (3,3), activation='relu'))\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 110, 110, 256)     93184     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 55, 55, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 51, 51, 128)       819328    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 25, 25, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 23, 23, 96)        110688    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 21, 64)        55360     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 16)          9232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,125,361\n",
      "Trainable params: 1,125,105\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD', metrics=['accuracy'],loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping(monitor='loss', patience=9, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "251/251 [==============================] - 130s 505ms/step - loss: 0.7235 - accuracy: 0.5143 - val_loss: 0.6858 - val_accuracy: 0.5615\n",
      "Epoch 2/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.6760 - accuracy: 0.5763 - val_loss: 0.6699 - val_accuracy: 0.5872\n",
      "Epoch 3/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.6654 - accuracy: 0.5973 - val_loss: 0.7074 - val_accuracy: 0.5304\n",
      "Epoch 4/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.6635 - accuracy: 0.6012 - val_loss: 0.6610 - val_accuracy: 0.6085\n",
      "Epoch 5/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.6465 - accuracy: 0.6318 - val_loss: 0.6610 - val_accuracy: 0.5957\n",
      "Epoch 6/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.6345 - accuracy: 0.6479 - val_loss: 0.6216 - val_accuracy: 0.6569\n",
      "Epoch 7/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.6259 - accuracy: 0.6535 - val_loss: 0.6478 - val_accuracy: 0.6199\n",
      "Epoch 8/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.6139 - accuracy: 0.6556 - val_loss: 0.6697 - val_accuracy: 0.5645\n",
      "Epoch 9/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.5999 - accuracy: 0.6741 - val_loss: 0.6234 - val_accuracy: 0.6416\n",
      "Epoch 10/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.5944 - accuracy: 0.6874 - val_loss: 0.6323 - val_accuracy: 0.6342\n",
      "Epoch 11/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.5838 - accuracy: 0.6981 - val_loss: 0.5845 - val_accuracy: 0.6861\n",
      "Epoch 12/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.5658 - accuracy: 0.7068 - val_loss: 0.5814 - val_accuracy: 0.6846\n",
      "Epoch 13/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.5636 - accuracy: 0.7098 - val_loss: 0.5805 - val_accuracy: 0.6960\n",
      "Epoch 14/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.5540 - accuracy: 0.7130 - val_loss: 0.6202 - val_accuracy: 0.6451\n",
      "Epoch 15/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.5459 - accuracy: 0.7284 - val_loss: 0.5544 - val_accuracy: 0.7113\n",
      "Epoch 16/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.5312 - accuracy: 0.7381 - val_loss: 0.5509 - val_accuracy: 0.7222\n",
      "Epoch 17/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.5154 - accuracy: 0.7462 - val_loss: 0.5986 - val_accuracy: 0.6866\n",
      "Epoch 18/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.5057 - accuracy: 0.7522 - val_loss: 0.8880 - val_accuracy: 0.5635\n",
      "Epoch 19/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.4925 - accuracy: 0.7652 - val_loss: 0.5028 - val_accuracy: 0.7593\n",
      "Epoch 20/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.4895 - accuracy: 0.7630 - val_loss: 0.4911 - val_accuracy: 0.7617\n",
      "Epoch 21/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.4834 - accuracy: 0.7731 - val_loss: 0.4285 - val_accuracy: 0.8028\n",
      "Epoch 22/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.4897 - accuracy: 0.7645 - val_loss: 0.5205 - val_accuracy: 0.7519\n",
      "Epoch 23/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.4717 - accuracy: 0.7756 - val_loss: 0.4352 - val_accuracy: 0.8097\n",
      "Epoch 24/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.4511 - accuracy: 0.7898 - val_loss: 0.5630 - val_accuracy: 0.7247\n",
      "Epoch 25/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.4505 - accuracy: 0.7867 - val_loss: 0.4874 - val_accuracy: 0.7652\n",
      "Epoch 26/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.4361 - accuracy: 0.8015 - val_loss: 0.4169 - val_accuracy: 0.8166\n",
      "Epoch 27/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.4351 - accuracy: 0.7905 - val_loss: 0.3790 - val_accuracy: 0.8374\n",
      "Epoch 28/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.4093 - accuracy: 0.8166 - val_loss: 0.4375 - val_accuracy: 0.7983\n",
      "Epoch 29/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.3955 - accuracy: 0.8191 - val_loss: 0.4382 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.4043 - accuracy: 0.8157 - val_loss: 0.3804 - val_accuracy: 0.8369\n",
      "Epoch 31/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.4021 - accuracy: 0.8121 - val_loss: 0.4779 - val_accuracy: 0.7988\n",
      "Epoch 32/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.3985 - accuracy: 0.8199 - val_loss: 0.6755 - val_accuracy: 0.7009\n",
      "Epoch 33/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.3844 - accuracy: 0.8286 - val_loss: 0.3547 - val_accuracy: 0.8522\n",
      "Epoch 34/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.3645 - accuracy: 0.8365 - val_loss: 0.3402 - val_accuracy: 0.8507\n",
      "Epoch 35/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.3748 - accuracy: 0.8248 - val_loss: 0.3453 - val_accuracy: 0.8497\n",
      "Epoch 36/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.3738 - accuracy: 0.8303 - val_loss: 0.5134 - val_accuracy: 0.7306\n",
      "Epoch 37/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.3441 - accuracy: 0.8508 - val_loss: 0.4104 - val_accuracy: 0.8206\n",
      "Epoch 38/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.3484 - accuracy: 0.8494 - val_loss: 0.4640 - val_accuracy: 0.7815\n",
      "Epoch 39/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.3287 - accuracy: 0.8587 - val_loss: 0.3666 - val_accuracy: 0.8512\n",
      "Epoch 40/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.3270 - accuracy: 0.8535 - val_loss: 0.3695 - val_accuracy: 0.8369\n",
      "Epoch 41/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.3294 - accuracy: 0.8574 - val_loss: 0.3188 - val_accuracy: 0.8646\n",
      "Epoch 42/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.3233 - accuracy: 0.8559 - val_loss: 0.3686 - val_accuracy: 0.8314\n",
      "Epoch 43/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.3136 - accuracy: 0.8670 - val_loss: 0.4076 - val_accuracy: 0.8082\n",
      "Epoch 44/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.3254 - accuracy: 0.8585 - val_loss: 0.3730 - val_accuracy: 0.8364\n",
      "Epoch 45/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.2931 - accuracy: 0.8749 - val_loss: 0.3469 - val_accuracy: 0.8507\n",
      "Epoch 46/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.2935 - accuracy: 0.8723 - val_loss: 0.3273 - val_accuracy: 0.8651\n",
      "Epoch 47/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2934 - accuracy: 0.8722 - val_loss: 0.3533 - val_accuracy: 0.8398\n",
      "Epoch 48/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2885 - accuracy: 0.8750 - val_loss: 0.3285 - val_accuracy: 0.8596\n",
      "Epoch 49/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2993 - accuracy: 0.8711 - val_loss: 0.2973 - val_accuracy: 0.8759\n",
      "Epoch 50/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2809 - accuracy: 0.8797 - val_loss: 0.3232 - val_accuracy: 0.8616\n",
      "Epoch 51/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2869 - accuracy: 0.8782 - val_loss: 0.3400 - val_accuracy: 0.8517\n",
      "Epoch 52/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2805 - accuracy: 0.8780 - val_loss: 0.3198 - val_accuracy: 0.8784\n",
      "Epoch 53/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2651 - accuracy: 0.8918 - val_loss: 0.3103 - val_accuracy: 0.8641\n",
      "Epoch 54/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2825 - accuracy: 0.8851 - val_loss: 0.3078 - val_accuracy: 0.8695\n",
      "Epoch 55/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2654 - accuracy: 0.8825 - val_loss: 0.3383 - val_accuracy: 0.8749\n",
      "Epoch 56/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2674 - accuracy: 0.8902 - val_loss: 0.2777 - val_accuracy: 0.8828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.2734 - accuracy: 0.8834 - val_loss: 0.3099 - val_accuracy: 0.8749\n",
      "Epoch 58/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.2552 - accuracy: 0.8935 - val_loss: 0.2695 - val_accuracy: 0.8878\n",
      "Epoch 59/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2527 - accuracy: 0.8911 - val_loss: 0.3265 - val_accuracy: 0.8606\n",
      "Epoch 60/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2555 - accuracy: 0.8939 - val_loss: 0.2780 - val_accuracy: 0.8838\n",
      "Epoch 61/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2424 - accuracy: 0.8962 - val_loss: 0.2695 - val_accuracy: 0.8903\n",
      "Epoch 62/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2492 - accuracy: 0.8887 - val_loss: 0.3105 - val_accuracy: 0.8705\n",
      "Epoch 63/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2363 - accuracy: 0.9022 - val_loss: 0.2518 - val_accuracy: 0.8997\n",
      "Epoch 64/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2335 - accuracy: 0.8954 - val_loss: 0.2857 - val_accuracy: 0.8814\n",
      "Epoch 65/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2408 - accuracy: 0.8990 - val_loss: 0.2808 - val_accuracy: 0.8843\n",
      "Epoch 66/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2387 - accuracy: 0.9039 - val_loss: 0.2558 - val_accuracy: 0.8957\n",
      "Epoch 67/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2255 - accuracy: 0.9075 - val_loss: 0.3029 - val_accuracy: 0.8898\n",
      "Epoch 68/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2179 - accuracy: 0.9101 - val_loss: 0.2577 - val_accuracy: 0.8898\n",
      "Epoch 69/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.2102 - accuracy: 0.9119 - val_loss: 0.2671 - val_accuracy: 0.8868\n",
      "Epoch 70/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.1986 - accuracy: 0.9202 - val_loss: 0.2622 - val_accuracy: 0.8932\n",
      "Epoch 71/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2078 - accuracy: 0.9132 - val_loss: 0.2623 - val_accuracy: 0.8922\n",
      "Epoch 72/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2104 - accuracy: 0.9132 - val_loss: 0.2679 - val_accuracy: 0.8987\n",
      "Epoch 73/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2072 - accuracy: 0.9050 - val_loss: 0.2708 - val_accuracy: 0.8917\n",
      "Epoch 74/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.2105 - accuracy: 0.9089 - val_loss: 0.2539 - val_accuracy: 0.8977\n",
      "Epoch 75/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1989 - accuracy: 0.9217 - val_loss: 0.2655 - val_accuracy: 0.8937\n",
      "Epoch 76/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2058 - accuracy: 0.9098 - val_loss: 0.2954 - val_accuracy: 0.8819\n",
      "Epoch 77/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2094 - accuracy: 0.9127 - val_loss: 0.2841 - val_accuracy: 0.8893\n",
      "Epoch 78/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.2091 - accuracy: 0.9115 - val_loss: 0.3023 - val_accuracy: 0.8883\n",
      "Epoch 79/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1740 - accuracy: 0.9304 - val_loss: 0.3063 - val_accuracy: 0.8868\n",
      "Epoch 80/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.2050 - accuracy: 0.9133 - val_loss: 0.2701 - val_accuracy: 0.8937\n",
      "Epoch 81/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1869 - accuracy: 0.9232 - val_loss: 0.2725 - val_accuracy: 0.8883\n",
      "Epoch 82/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1870 - accuracy: 0.9220 - val_loss: 0.3110 - val_accuracy: 0.8774\n",
      "Epoch 83/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1879 - accuracy: 0.9230 - val_loss: 0.2902 - val_accuracy: 0.8735\n",
      "Epoch 84/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1843 - accuracy: 0.9228 - val_loss: 0.2616 - val_accuracy: 0.9026\n",
      "Epoch 85/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1881 - accuracy: 0.9189 - val_loss: 0.2416 - val_accuracy: 0.9041\n",
      "Epoch 86/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1733 - accuracy: 0.9286 - val_loss: 0.2549 - val_accuracy: 0.8927\n",
      "Epoch 87/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1728 - accuracy: 0.9278 - val_loss: 0.3822 - val_accuracy: 0.8586\n",
      "Epoch 88/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1776 - accuracy: 0.9274 - val_loss: 0.2596 - val_accuracy: 0.8937\n",
      "Epoch 89/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1752 - accuracy: 0.9320 - val_loss: 0.2809 - val_accuracy: 0.8972\n",
      "Epoch 90/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1637 - accuracy: 0.9300 - val_loss: 0.2399 - val_accuracy: 0.9120\n",
      "Epoch 91/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1672 - accuracy: 0.9306 - val_loss: 0.2679 - val_accuracy: 0.8927\n",
      "Epoch 92/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1817 - accuracy: 0.9291 - val_loss: 0.2708 - val_accuracy: 0.8828\n",
      "Epoch 93/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1623 - accuracy: 0.9342 - val_loss: 0.3026 - val_accuracy: 0.8814\n",
      "Epoch 94/150\n",
      "251/251 [==============================] - 58s 229ms/step - loss: 0.1583 - accuracy: 0.9338 - val_loss: 0.3043 - val_accuracy: 0.8774\n",
      "Epoch 95/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1670 - accuracy: 0.9294 - val_loss: 0.2901 - val_accuracy: 0.8922\n",
      "Epoch 96/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1589 - accuracy: 0.9355 - val_loss: 0.3865 - val_accuracy: 0.8552\n",
      "Epoch 97/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1652 - accuracy: 0.9347 - val_loss: 0.2567 - val_accuracy: 0.8997\n",
      "Epoch 98/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1660 - accuracy: 0.9318 - val_loss: 0.2346 - val_accuracy: 0.9090\n",
      "Epoch 99/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1711 - accuracy: 0.9306 - val_loss: 0.2505 - val_accuracy: 0.8992\n",
      "Epoch 100/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1506 - accuracy: 0.9358 - val_loss: 0.2632 - val_accuracy: 0.9006\n",
      "Epoch 101/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.1544 - accuracy: 0.9361 - val_loss: 0.2536 - val_accuracy: 0.8952\n",
      "Epoch 102/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.1468 - accuracy: 0.9423 - val_loss: 0.2619 - val_accuracy: 0.9071\n",
      "Epoch 103/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.1592 - accuracy: 0.9372 - val_loss: 0.2854 - val_accuracy: 0.8898\n",
      "Epoch 104/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1814 - accuracy: 0.9301 - val_loss: 0.2569 - val_accuracy: 0.9041\n",
      "Epoch 105/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1589 - accuracy: 0.9351 - val_loss: 0.2639 - val_accuracy: 0.9011\n",
      "Epoch 106/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1501 - accuracy: 0.9410 - val_loss: 0.2538 - val_accuracy: 0.9026\n",
      "Epoch 107/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.1390 - accuracy: 0.9475 - val_loss: 0.2730 - val_accuracy: 0.9016\n",
      "Epoch 108/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1434 - accuracy: 0.9405 - val_loss: 0.2621 - val_accuracy: 0.9036\n",
      "Epoch 109/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1357 - accuracy: 0.9417 - val_loss: 0.2554 - val_accuracy: 0.9041\n",
      "Epoch 110/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.1355 - accuracy: 0.9467 - val_loss: 0.2733 - val_accuracy: 0.9081\n",
      "Epoch 111/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1409 - accuracy: 0.9412 - val_loss: 0.3334 - val_accuracy: 0.8913\n",
      "Epoch 112/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1427 - accuracy: 0.9410 - val_loss: 0.2798 - val_accuracy: 0.9120\n",
      "Epoch 113/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.1303 - accuracy: 0.9467 - val_loss: 0.2876 - val_accuracy: 0.9076\n",
      "Epoch 114/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.1229 - accuracy: 0.9515 - val_loss: 0.2747 - val_accuracy: 0.9006\n",
      "Epoch 115/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1132 - accuracy: 0.9537 - val_loss: 0.2691 - val_accuracy: 0.9016\n",
      "Epoch 116/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.1289 - accuracy: 0.9468 - val_loss: 0.2408 - val_accuracy: 0.9150\n",
      "Epoch 117/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.1392 - accuracy: 0.9450 - val_loss: 0.2552 - val_accuracy: 0.9081\n",
      "Epoch 118/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.1343 - accuracy: 0.9435 - val_loss: 0.3103 - val_accuracy: 0.8913\n",
      "Epoch 119/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1196 - accuracy: 0.9528 - val_loss: 0.2553 - val_accuracy: 0.9071\n",
      "Epoch 120/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.1223 - accuracy: 0.9529 - val_loss: 0.2781 - val_accuracy: 0.9056\n",
      "Epoch 121/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1100 - accuracy: 0.9568 - val_loss: 0.2743 - val_accuracy: 0.9031\n",
      "Epoch 122/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1200 - accuracy: 0.9521 - val_loss: 0.2279 - val_accuracy: 0.9150\n",
      "Epoch 123/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1309 - accuracy: 0.9462 - val_loss: 0.2886 - val_accuracy: 0.9051\n",
      "Epoch 124/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1257 - accuracy: 0.9526 - val_loss: 0.2894 - val_accuracy: 0.8977\n",
      "Epoch 125/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1217 - accuracy: 0.9498 - val_loss: 0.2626 - val_accuracy: 0.9150\n",
      "Epoch 126/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.1123 - accuracy: 0.9562 - val_loss: 0.2989 - val_accuracy: 0.8932\n",
      "Epoch 127/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.1239 - accuracy: 0.9490 - val_loss: 0.2584 - val_accuracy: 0.9046\n",
      "Epoch 128/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.1132 - accuracy: 0.9523 - val_loss: 0.2658 - val_accuracy: 0.9140\n",
      "Epoch 129/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.1299 - accuracy: 0.9456 - val_loss: 0.2816 - val_accuracy: 0.9066\n",
      "Epoch 130/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1208 - accuracy: 0.9520 - val_loss: 0.2636 - val_accuracy: 0.9179\n",
      "Epoch 131/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.1088 - accuracy: 0.9576 - val_loss: 0.5034 - val_accuracy: 0.7588\n",
      "Epoch 132/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.1384 - accuracy: 0.9444 - val_loss: 0.3210 - val_accuracy: 0.9086\n",
      "Epoch 133/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.0945 - accuracy: 0.9619 - val_loss: 0.3154 - val_accuracy: 0.9051\n",
      "Epoch 134/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.0996 - accuracy: 0.9624 - val_loss: 0.2581 - val_accuracy: 0.9140\n",
      "Epoch 135/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1062 - accuracy: 0.9588 - val_loss: 0.4891 - val_accuracy: 0.8240\n",
      "Epoch 136/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.0992 - accuracy: 0.9628 - val_loss: 0.2513 - val_accuracy: 0.9160\n",
      "Epoch 137/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1104 - accuracy: 0.9556 - val_loss: 0.2731 - val_accuracy: 0.8957\n",
      "Epoch 138/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.0982 - accuracy: 0.9616 - val_loss: 0.2683 - val_accuracy: 0.9140\n",
      "Epoch 139/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1200 - accuracy: 0.9509 - val_loss: 0.2853 - val_accuracy: 0.9026\n",
      "Epoch 140/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.1003 - accuracy: 0.9616 - val_loss: 0.2654 - val_accuracy: 0.9145\n",
      "Epoch 141/150\n",
      "251/251 [==============================] - 58s 231ms/step - loss: 0.1002 - accuracy: 0.9593 - val_loss: 0.2874 - val_accuracy: 0.9110\n",
      "Epoch 142/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1033 - accuracy: 0.9562 - val_loss: 0.2742 - val_accuracy: 0.9145\n",
      "Epoch 143/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.0912 - accuracy: 0.9660 - val_loss: 0.2320 - val_accuracy: 0.9219\n",
      "Epoch 144/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.0938 - accuracy: 0.9650 - val_loss: 0.3300 - val_accuracy: 0.8967\n",
      "Epoch 145/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1019 - accuracy: 0.9594 - val_loss: 0.2817 - val_accuracy: 0.9061\n",
      "Epoch 146/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.0905 - accuracy: 0.9669 - val_loss: 0.3293 - val_accuracy: 0.8997\n",
      "Epoch 147/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.0966 - accuracy: 0.9604 - val_loss: 0.2232 - val_accuracy: 0.9174\n",
      "Epoch 148/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.0971 - accuracy: 0.9646 - val_loss: 0.2973 - val_accuracy: 0.9076\n",
      "Epoch 149/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.0905 - accuracy: 0.9646 - val_loss: 0.4968 - val_accuracy: 0.8735\n",
      "Epoch 150/150\n",
      "251/251 [==============================] - 58s 230ms/step - loss: 0.1009 - accuracy: 0.9592 - val_loss: 0.3637 - val_accuracy: 0.8739\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, epochs=150, callbacks=[callback], validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'r', label='training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='test accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
