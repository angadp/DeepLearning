{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "source = './data/images/images'\n",
    "dest = './data/test'\n",
    "\n",
    "dirs = os.listdir(source)\n",
    "\n",
    "for d in dirs:\n",
    "    files = os.listdir(source + '/' + d)\n",
    "    for f in files:\n",
    "        if(np.random.rand(1) < 0.1):\n",
    "            os.makedirs(os.path.dirname(dest + '/' + d + '/' + f), exist_ok = True)\n",
    "            shutil.move(source + '/' + d + '/' + f, dest + '/' + d + '/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18514 images belonging to 120 classes.\n",
      "Found 2063 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    rescale=1/255.0,\n",
    "    zoom_range=0.15,\n",
    "    rotation_range=15,\n",
    "    height_shift_range=0.15,\n",
    "    width_shift_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "test_generator = ImageDataGenerator(\n",
    "    rescale=1/255.0\n",
    ")\n",
    "\n",
    "training_data = train_generator.flow_from_directory('./data/images/images', class_mode='categorical', batch_size=32, target_size=(227, 227))\n",
    "test_data = test_generator.flow_from_directory('./data/test', class_mode='categorical', batch_size=32, target_size=(227, 227))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout, Dense, Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = Input(shape=(227,227,3))\n",
    "\n",
    "tower_1 = Conv2D(96, (5, 5))(input_shape)\n",
    "tower_1 = MaxPooling2D((2,2))(tower_1)\n",
    "tower_1 = BatchNormalization()(tower_1)\n",
    "\n",
    "tower_2 = MaxPooling2D((2, 2))(input_shape)\n",
    "tower_2 = Conv2D(96, (2, 2))(tower_2)\n",
    "tower_2 = Dropout(0.15)(tower_2)\n",
    "tower_2 = Conv2D(96, (2, 2))(tower_2)\n",
    "\n",
    "tower_3 = MaxPooling2D((2, 2))(input_shape)\n",
    "tower_3 = Conv2D(96, (3, 3))(tower_3)\n",
    "\n",
    "concat = Average()([tower_1, tower_2, tower_3])\n",
    "\n",
    "out = MaxPooling2D(3,3)(concat)\n",
    "\n",
    "tower_1 = Conv2D(64,(4,4), activation='relu')(out)\n",
    "tower_1 = BatchNormalization()(tower_1)\n",
    "tower_1 = Conv2D(32,(3,3))(tower_1)\n",
    "tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "tower_1 = Dropout(0.15)(tower_1)\n",
    "tower_1 = Conv2D(32,(3,3))(tower_1)\n",
    "tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "\n",
    "tower_2 = Conv2D(64,(3,3))(out)\n",
    "tower_2 = MaxPooling2D(2,2)(tower_2)\n",
    "tower_2 = Dropout(0.15)(tower_2)\n",
    "tower_2 = Conv2D(32,(3,3), activation='relu')(tower_2)\n",
    "tower_2 = MaxPooling2D(2,2)(tower_2)\n",
    "tower_2 = BatchNormalization()(tower_2)\n",
    "\n",
    "concat = Average()([tower_1, tower_2])\n",
    "\n",
    "out = Flatten()(concat)\n",
    "\n",
    "out = Dense(512, activation='relu')(out)\n",
    "out = Dropout(0.15)(out)\n",
    "\n",
    "out = Dense(256, activation='relu')(out)\n",
    "\n",
    "out = Dense(120, activation='softmax')(out)\n",
    "\n",
    "model = Model(input_shape, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 227, 227, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 113, 113, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 223, 223, 96) 7296        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 112, 112, 96) 1248        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 111, 111, 96) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 112, 112, 96) 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 113, 113, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 111, 111, 96) 384         max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 111, 111, 96) 36960       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 111, 111, 96) 2688        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "average_1 (Average)             (None, 111, 111, 96) 0           batch_normalization_1[0][0]      \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 37, 37, 96)   0           average_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 34, 34, 64)   98368       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 34, 34, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 64)   55360       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 32)   18464       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 17, 17, 64)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 32)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 17, 17, 64)   0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 16, 32)   0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 15, 15, 32)   18464       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 14, 14, 32)   9248        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 7, 7, 32)     0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 7, 7, 32)     0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 7, 7, 32)     128         max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "average_2 (Average)             (None, 7, 7, 32)     0           max_pooling2d_8[0][0]            \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1568)         0           average_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          803328      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          131328      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 120)          30840       dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,214,360\n",
      "Trainable params: 1,213,976\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='SGD', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "579/579 [==============================] - 484s 837ms/step - loss: 4.7895 - accuracy: 0.0145 - val_loss: 4.7377 - val_accuracy: 0.0218\n",
      "Epoch 2/500\n",
      "579/579 [==============================] - 497s 859ms/step - loss: 4.6519 - accuracy: 0.0255 - val_loss: 4.6733 - val_accuracy: 0.0257\n",
      "Epoch 3/500\n",
      "579/579 [==============================] - 494s 852ms/step - loss: 4.5410 - accuracy: 0.0329 - val_loss: 4.5442 - val_accuracy: 0.0334\n",
      "Epoch 4/500\n",
      "579/579 [==============================] - 492s 849ms/step - loss: 4.4725 - accuracy: 0.0379 - val_loss: 4.6442 - val_accuracy: 0.0402\n",
      "Epoch 5/500\n",
      "579/579 [==============================] - 490s 846ms/step - loss: 4.4076 - accuracy: 0.0439 - val_loss: 4.0768 - val_accuracy: 0.0402\n",
      "Epoch 6/500\n",
      "579/579 [==============================] - 489s 845ms/step - loss: 4.3523 - accuracy: 0.0508 - val_loss: 4.4186 - val_accuracy: 0.0596\n",
      "Epoch 7/500\n",
      "579/579 [==============================] - 495s 855ms/step - loss: 4.3001 - accuracy: 0.0546 - val_loss: 4.2764 - val_accuracy: 0.0533\n",
      "Epoch 8/500\n",
      "579/579 [==============================] - 488s 843ms/step - loss: 4.2445 - accuracy: 0.0635 - val_loss: 4.2376 - val_accuracy: 0.0645\n",
      "Epoch 9/500\n",
      "579/579 [==============================] - 486s 839ms/step - loss: 4.1982 - accuracy: 0.0689 - val_loss: 4.2395 - val_accuracy: 0.0688\n",
      "Epoch 10/500\n",
      "579/579 [==============================] - 488s 843ms/step - loss: 4.1538 - accuracy: 0.0721 - val_loss: 4.0047 - val_accuracy: 0.0553\n",
      "Epoch 11/500\n",
      "579/579 [==============================] - 487s 842ms/step - loss: 4.1199 - accuracy: 0.0759 - val_loss: 4.4706 - val_accuracy: 0.0698\n",
      "Epoch 12/500\n",
      "579/579 [==============================] - 491s 848ms/step - loss: 4.0782 - accuracy: 0.0843 - val_loss: 3.7135 - val_accuracy: 0.0926\n",
      "Epoch 13/500\n",
      "579/579 [==============================] - 493s 852ms/step - loss: 4.0357 - accuracy: 0.0862 - val_loss: 4.4617 - val_accuracy: 0.0776\n",
      "Epoch 14/500\n",
      "579/579 [==============================] - 504s 870ms/step - loss: 4.0168 - accuracy: 0.0925 - val_loss: 4.4650 - val_accuracy: 0.0824\n",
      "Epoch 15/500\n",
      "579/579 [==============================] - 495s 855ms/step - loss: 3.9814 - accuracy: 0.0932 - val_loss: 4.3992 - val_accuracy: 0.0814\n",
      "Epoch 16/500\n",
      "579/579 [==============================] - 494s 854ms/step - loss: 3.9562 - accuracy: 0.0975 - val_loss: 5.7627 - val_accuracy: 0.0407\n",
      "Epoch 17/500\n",
      "579/579 [==============================] - 493s 852ms/step - loss: 3.9188 - accuracy: 0.0998 - val_loss: 4.0190 - val_accuracy: 0.0708\n",
      "Epoch 18/500\n",
      "579/579 [==============================] - 489s 845ms/step - loss: 3.8896 - accuracy: 0.1100 - val_loss: 4.1991 - val_accuracy: 0.0698\n",
      "Epoch 19/500\n",
      "579/579 [==============================] - 491s 847ms/step - loss: 3.8617 - accuracy: 0.1126 - val_loss: 4.3841 - val_accuracy: 0.1008\n",
      "Epoch 20/500\n",
      "579/579 [==============================] - 493s 851ms/step - loss: 3.8445 - accuracy: 0.1126 - val_loss: 3.7088 - val_accuracy: 0.0979\n",
      "Epoch 21/500\n",
      "579/579 [==============================] - 490s 847ms/step - loss: 3.8205 - accuracy: 0.1169 - val_loss: 4.7429 - val_accuracy: 0.0882\n",
      "Epoch 22/500\n",
      "579/579 [==============================] - 494s 853ms/step - loss: 3.7806 - accuracy: 0.1245 - val_loss: 4.0679 - val_accuracy: 0.0776\n",
      "Epoch 23/500\n",
      "579/579 [==============================] - 497s 858ms/step - loss: 3.7646 - accuracy: 0.1263 - val_loss: 4.1106 - val_accuracy: 0.1076\n",
      "Epoch 24/500\n",
      "579/579 [==============================] - 501s 866ms/step - loss: 3.7260 - accuracy: 0.1298 - val_loss: 4.0844 - val_accuracy: 0.1062\n",
      "Epoch 25/500\n",
      "579/579 [==============================] - 487s 842ms/step - loss: 3.7143 - accuracy: 0.1339 - val_loss: 4.2534 - val_accuracy: 0.1125\n",
      "Epoch 26/500\n",
      "579/579 [==============================] - 486s 840ms/step - loss: 3.6779 - accuracy: 0.1410 - val_loss: 4.1345 - val_accuracy: 0.0931\n",
      "Epoch 27/500\n",
      "579/579 [==============================] - 489s 845ms/step - loss: 3.6606 - accuracy: 0.1415 - val_loss: 3.5160 - val_accuracy: 0.1139\n",
      "Epoch 28/500\n",
      "579/579 [==============================] - 488s 843ms/step - loss: 3.6377 - accuracy: 0.1432 - val_loss: 3.8594 - val_accuracy: 0.0839\n",
      "Epoch 29/500\n",
      "579/579 [==============================] - 492s 850ms/step - loss: 3.6122 - accuracy: 0.1496 - val_loss: 4.5626 - val_accuracy: 0.1047\n",
      "Epoch 30/500\n",
      "579/579 [==============================] - 492s 849ms/step - loss: 3.5886 - accuracy: 0.1508 - val_loss: 4.1991 - val_accuracy: 0.0950\n",
      "Epoch 31/500\n",
      "579/579 [==============================] - 501s 865ms/step - loss: 3.5591 - accuracy: 0.1556 - val_loss: 4.0952 - val_accuracy: 0.0780\n",
      "Epoch 32/500\n",
      "579/579 [==============================] - 485s 838ms/step - loss: 3.5466 - accuracy: 0.1614 - val_loss: 4.2391 - val_accuracy: 0.1425\n",
      "Epoch 33/500\n",
      "579/579 [==============================] - 486s 839ms/step - loss: 3.5255 - accuracy: 0.1630 - val_loss: 4.0068 - val_accuracy: 0.1183\n",
      "Epoch 34/500\n",
      "579/579 [==============================] - 488s 843ms/step - loss: 3.4952 - accuracy: 0.1694 - val_loss: 3.5784 - val_accuracy: 0.1173\n",
      "Epoch 35/500\n",
      "579/579 [==============================] - 486s 840ms/step - loss: 3.4809 - accuracy: 0.1695 - val_loss: 4.3201 - val_accuracy: 0.1062\n",
      "Epoch 36/500\n",
      "579/579 [==============================] - 486s 839ms/step - loss: 3.4642 - accuracy: 0.1693 - val_loss: 4.2253 - val_accuracy: 0.1430\n",
      "Epoch 37/500\n",
      "579/579 [==============================] - 487s 841ms/step - loss: 3.4454 - accuracy: 0.1713 - val_loss: 3.8094 - val_accuracy: 0.1285\n",
      "Epoch 38/500\n",
      "579/579 [==============================] - 489s 845ms/step - loss: 3.4181 - accuracy: 0.1785 - val_loss: 3.4006 - val_accuracy: 0.1595\n",
      "Epoch 39/500\n",
      "579/579 [==============================] - 523s 904ms/step - loss: 3.3992 - accuracy: 0.1795 - val_loss: 3.6478 - val_accuracy: 0.1401\n",
      "Epoch 40/500\n",
      "579/579 [==============================] - 488s 843ms/step - loss: 3.3772 - accuracy: 0.1849 - val_loss: 3.5979 - val_accuracy: 0.1095\n",
      "Epoch 41/500\n",
      "579/579 [==============================] - 489s 845ms/step - loss: 3.3749 - accuracy: 0.1904 - val_loss: 3.3434 - val_accuracy: 0.1197\n",
      "Epoch 42/500\n",
      "579/579 [==============================] - 488s 844ms/step - loss: 3.3492 - accuracy: 0.1933 - val_loss: 3.5328 - val_accuracy: 0.0955\n",
      "Epoch 43/500\n",
      "579/579 [==============================] - 485s 838ms/step - loss: 3.3276 - accuracy: 0.1967 - val_loss: 3.6591 - val_accuracy: 0.1469\n",
      "Epoch 44/500\n",
      "579/579 [==============================] - 486s 839ms/step - loss: 3.3019 - accuracy: 0.2007 - val_loss: 3.9687 - val_accuracy: 0.1013\n",
      "Epoch 45/500\n",
      "579/579 [==============================] - 488s 844ms/step - loss: 3.2954 - accuracy: 0.1988 - val_loss: 4.7422 - val_accuracy: 0.1580\n",
      "Epoch 46/500\n",
      "579/579 [==============================] - 488s 843ms/step - loss: 3.2641 - accuracy: 0.2063 - val_loss: 3.8074 - val_accuracy: 0.1580\n",
      "Epoch 47/500\n",
      "579/579 [==============================] - 489s 844ms/step - loss: 3.2444 - accuracy: 0.2061 - val_loss: 3.4736 - val_accuracy: 0.1803\n",
      "Epoch 48/500\n",
      "579/579 [==============================] - 483s 835ms/step - loss: 3.2423 - accuracy: 0.2077 - val_loss: 3.3485 - val_accuracy: 0.1241\n",
      "Epoch 49/500\n",
      "579/579 [==============================] - 497s 858ms/step - loss: 3.2244 - accuracy: 0.2105 - val_loss: 3.7155 - val_accuracy: 0.1600\n",
      "Epoch 50/500\n",
      "579/579 [==============================] - 485s 837ms/step - loss: 3.1926 - accuracy: 0.2165 - val_loss: 4.0033 - val_accuracy: 0.1682\n",
      "Epoch 51/500\n",
      "579/579 [==============================] - 490s 847ms/step - loss: 3.1872 - accuracy: 0.2193 - val_loss: 3.5728 - val_accuracy: 0.1352\n",
      "Epoch 52/500\n",
      "579/579 [==============================] - 496s 856ms/step - loss: 3.1710 - accuracy: 0.2206 - val_loss: 4.3442 - val_accuracy: 0.1643\n",
      "Epoch 53/500\n",
      "579/579 [==============================] - 487s 842ms/step - loss: 3.1526 - accuracy: 0.2224 - val_loss: 3.6207 - val_accuracy: 0.1721\n",
      "Epoch 54/500\n",
      "579/579 [==============================] - 485s 838ms/step - loss: 3.1372 - accuracy: 0.2269 - val_loss: 3.4175 - val_accuracy: 0.1716\n",
      "Epoch 55/500\n",
      "579/579 [==============================] - 485s 837ms/step - loss: 3.1227 - accuracy: 0.2313 - val_loss: 3.3723 - val_accuracy: 0.1769\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579/579 [==============================] - 481s 831ms/step - loss: 3.1072 - accuracy: 0.2293 - val_loss: 4.2737 - val_accuracy: 0.1357\n",
      "Epoch 57/500\n",
      "579/579 [==============================] - 481s 831ms/step - loss: 3.0892 - accuracy: 0.2365 - val_loss: 3.6963 - val_accuracy: 0.1638\n",
      "Epoch 58/500\n",
      "579/579 [==============================] - 485s 838ms/step - loss: 3.0682 - accuracy: 0.2384 - val_loss: 4.3622 - val_accuracy: 0.1401\n",
      "Epoch 59/500\n",
      "579/579 [==============================] - 486s 840ms/step - loss: 3.0743 - accuracy: 0.2377 - val_loss: 3.5792 - val_accuracy: 0.0960\n",
      "Epoch 60/500\n",
      "579/579 [==============================] - 504s 870ms/step - loss: 3.0462 - accuracy: 0.2402 - val_loss: 3.2067 - val_accuracy: 0.1750\n",
      "Epoch 61/500\n",
      "579/579 [==============================] - 485s 838ms/step - loss: 3.0280 - accuracy: 0.2451 - val_loss: 2.9762 - val_accuracy: 0.1459\n",
      "Epoch 62/500\n",
      "579/579 [==============================] - 485s 837ms/step - loss: 3.0086 - accuracy: 0.2509 - val_loss: 3.0457 - val_accuracy: 0.1556\n",
      "Epoch 63/500\n",
      "579/579 [==============================] - 483s 834ms/step - loss: 3.0046 - accuracy: 0.2515 - val_loss: 4.0351 - val_accuracy: 0.1309\n",
      "Epoch 64/500\n",
      "579/579 [==============================] - 484s 835ms/step - loss: 2.9878 - accuracy: 0.2521 - val_loss: 3.8205 - val_accuracy: 0.1871\n",
      "Epoch 65/500\n",
      "579/579 [==============================] - 487s 841ms/step - loss: 2.9752 - accuracy: 0.2573 - val_loss: 3.3433 - val_accuracy: 0.1794\n",
      "Epoch 66/500\n",
      "579/579 [==============================] - 493s 851ms/step - loss: 2.9715 - accuracy: 0.2559 - val_loss: 4.7875 - val_accuracy: 0.1813\n",
      "Epoch 67/500\n",
      "579/579 [==============================] - 492s 850ms/step - loss: 2.9601 - accuracy: 0.2594 - val_loss: 2.7722 - val_accuracy: 0.1774\n",
      "Epoch 68/500\n",
      "579/579 [==============================] - 491s 848ms/step - loss: 2.9437 - accuracy: 0.2606 - val_loss: 3.3756 - val_accuracy: 0.1789\n",
      "Epoch 69/500\n",
      "579/579 [==============================] - 500s 863ms/step - loss: 2.9232 - accuracy: 0.2681 - val_loss: 4.3899 - val_accuracy: 0.1794\n",
      "Epoch 70/500\n",
      "579/579 [==============================] - 487s 840ms/step - loss: 2.9150 - accuracy: 0.2639 - val_loss: 2.9426 - val_accuracy: 0.1687\n",
      "Epoch 71/500\n",
      "579/579 [==============================] - 489s 844ms/step - loss: 2.8864 - accuracy: 0.2733 - val_loss: 4.3891 - val_accuracy: 0.1372\n",
      "Epoch 72/500\n",
      "579/579 [==============================] - 486s 839ms/step - loss: 2.8865 - accuracy: 0.2750 - val_loss: 2.8467 - val_accuracy: 0.1634\n",
      "Epoch 73/500\n",
      "579/579 [==============================] - 491s 848ms/step - loss: 2.8743 - accuracy: 0.2716 - val_loss: 3.7727 - val_accuracy: 0.1750\n",
      "Epoch 74/500\n",
      "579/579 [==============================] - 507s 875ms/step - loss: 2.8675 - accuracy: 0.2745 - val_loss: 3.6280 - val_accuracy: 0.1818\n",
      "Epoch 75/500\n",
      "579/579 [==============================] - 487s 841ms/step - loss: 2.8453 - accuracy: 0.2817 - val_loss: 3.6847 - val_accuracy: 0.2113\n",
      "Epoch 76/500\n",
      "579/579 [==============================] - 485s 837ms/step - loss: 2.8280 - accuracy: 0.2809 - val_loss: 3.8474 - val_accuracy: 0.1721\n",
      "Epoch 77/500\n",
      "579/579 [==============================] - 497s 859ms/step - loss: 2.8216 - accuracy: 0.2818 - val_loss: 4.1568 - val_accuracy: 0.1255\n",
      "Epoch 78/500\n",
      "579/579 [==============================] - 490s 846ms/step - loss: 2.8187 - accuracy: 0.2812 - val_loss: 3.0142 - val_accuracy: 0.1934\n",
      "Epoch 79/500\n",
      "579/579 [==============================] - 490s 846ms/step - loss: 2.7904 - accuracy: 0.2911 - val_loss: 2.9184 - val_accuracy: 0.1857\n",
      "Epoch 80/500\n",
      "579/579 [==============================] - 489s 844ms/step - loss: 2.7921 - accuracy: 0.2902 - val_loss: 3.2516 - val_accuracy: 0.1808\n",
      "Epoch 81/500\n",
      "579/579 [==============================] - 489s 845ms/step - loss: 2.7875 - accuracy: 0.2876 - val_loss: 3.3363 - val_accuracy: 0.1944\n",
      "Epoch 82/500\n",
      "579/579 [==============================] - 496s 857ms/step - loss: 2.7506 - accuracy: 0.2937 - val_loss: 2.9111 - val_accuracy: 0.2099\n",
      "Epoch 83/500\n",
      "579/579 [==============================] - 490s 846ms/step - loss: 2.7579 - accuracy: 0.2964 - val_loss: 4.0650 - val_accuracy: 0.1435\n",
      "Epoch 84/500\n",
      "579/579 [==============================] - 506s 874ms/step - loss: 2.7437 - accuracy: 0.2974 - val_loss: 2.5000 - val_accuracy: 0.1895\n",
      "Epoch 85/500\n",
      "579/579 [==============================] - 498s 860ms/step - loss: 2.7181 - accuracy: 0.3033 - val_loss: 3.1777 - val_accuracy: 0.1721\n",
      "Epoch 86/500\n",
      "579/579 [==============================] - 487s 840ms/step - loss: 2.7191 - accuracy: 0.3026 - val_loss: 2.6212 - val_accuracy: 0.1861\n",
      "Epoch 87/500\n",
      "579/579 [==============================] - 485s 838ms/step - loss: 2.7049 - accuracy: 0.3052 - val_loss: 3.8038 - val_accuracy: 0.2288\n",
      "Epoch 88/500\n",
      "579/579 [==============================] - 498s 860ms/step - loss: 2.6976 - accuracy: 0.3066 - val_loss: 4.6265 - val_accuracy: 0.1372\n",
      "Epoch 89/500\n",
      "579/579 [==============================] - 524s 904ms/step - loss: 2.6819 - accuracy: 0.3072 - val_loss: 3.4540 - val_accuracy: 0.1604\n",
      "Epoch 90/500\n",
      "579/579 [==============================] - 571s 986ms/step - loss: 2.6804 - accuracy: 0.3101 - val_loss: 2.5335 - val_accuracy: 0.2036\n",
      "Epoch 91/500\n",
      "579/579 [==============================] - 517s 894ms/step - loss: 2.6770 - accuracy: 0.3095 - val_loss: 3.5736 - val_accuracy: 0.1740\n",
      "Epoch 92/500\n",
      "579/579 [==============================] - 569s 983ms/step - loss: 2.6437 - accuracy: 0.3157 - val_loss: 4.0459 - val_accuracy: 0.1871\n",
      "Epoch 93/500\n",
      "579/579 [==============================] - 506s 874ms/step - loss: 2.6483 - accuracy: 0.3158 - val_loss: 3.7072 - val_accuracy: 0.1813\n",
      "Epoch 94/500\n",
      "579/579 [==============================] - 546s 943ms/step - loss: 2.6313 - accuracy: 0.3190 - val_loss: 2.9771 - val_accuracy: 0.2079\n",
      "Epoch 95/500\n",
      "579/579 [==============================] - 583s 1s/step - loss: 2.6315 - accuracy: 0.3197 - val_loss: 2.7149 - val_accuracy: 0.2118\n",
      "Epoch 96/500\n",
      "579/579 [==============================] - 565s 975ms/step - loss: 2.6120 - accuracy: 0.3226 - val_loss: 2.6121 - val_accuracy: 0.2157\n",
      "Epoch 97/500\n",
      "579/579 [==============================] - 692s 1s/step - loss: 2.5916 - accuracy: 0.3272 - val_loss: 3.7070 - val_accuracy: 0.2041\n",
      "Epoch 98/500\n",
      "579/579 [==============================] - 713s 1s/step - loss: 2.5891 - accuracy: 0.3335 - val_loss: 4.2323 - val_accuracy: 0.1396\n",
      "Epoch 99/500\n",
      "579/579 [==============================] - 584s 1s/step - loss: 2.5858 - accuracy: 0.3302 - val_loss: 4.7597 - val_accuracy: 0.1721\n",
      "Epoch 100/500\n",
      "579/579 [==============================] - 550s 951ms/step - loss: 2.5654 - accuracy: 0.3328 - val_loss: 3.4653 - val_accuracy: 0.1813\n",
      "Epoch 101/500\n",
      "579/579 [==============================] - 490s 846ms/step - loss: 2.5632 - accuracy: 0.3328 - val_loss: 4.5617 - val_accuracy: 0.1600\n",
      "Epoch 102/500\n",
      "579/579 [==============================] - 490s 845ms/step - loss: 2.5604 - accuracy: 0.3355 - val_loss: 2.7764 - val_accuracy: 0.1939\n",
      "Epoch 103/500\n",
      "579/579 [==============================] - 495s 855ms/step - loss: 2.5452 - accuracy: 0.3335 - val_loss: 2.9519 - val_accuracy: 0.1934\n",
      "Epoch 104/500\n",
      "579/579 [==============================] - 628s 1s/step - loss: 2.5337 - accuracy: 0.3360 - val_loss: 3.7990 - val_accuracy: 0.1823\n",
      "Epoch 105/500\n",
      "579/579 [==============================] - 507s 875ms/step - loss: 2.5201 - accuracy: 0.3424 - val_loss: 3.5500 - val_accuracy: 0.1687\n",
      "Epoch 106/500\n",
      "579/579 [==============================] - 587s 1s/step - loss: 2.5140 - accuracy: 0.3421 - val_loss: 3.4398 - val_accuracy: 0.2210\n",
      "Epoch 107/500\n",
      "579/579 [==============================] - 691s 1s/step - loss: 2.4869 - accuracy: 0.3462 - val_loss: 3.8164 - val_accuracy: 0.2269\n",
      "Epoch 108/500\n",
      "579/579 [==============================] - 659s 1s/step - loss: 2.4867 - accuracy: 0.3492 - val_loss: 3.5314 - val_accuracy: 0.1774\n",
      "Epoch 109/500\n",
      "579/579 [==============================] - 561s 970ms/step - loss: 2.4799 - accuracy: 0.3482 - val_loss: 4.8672 - val_accuracy: 0.1488\n",
      "Epoch 110/500\n",
      "579/579 [==============================] - 587s 1s/step - loss: 2.4827 - accuracy: 0.3500 - val_loss: 3.6047 - val_accuracy: 0.2404\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579/579 [==============================] - 483s 835ms/step - loss: 2.4781 - accuracy: 0.3500 - val_loss: 4.4581 - val_accuracy: 0.2046\n",
      "Epoch 112/500\n",
      "579/579 [==============================] - 488s 842ms/step - loss: 2.4506 - accuracy: 0.3554 - val_loss: 4.0158 - val_accuracy: 0.1861\n",
      "Epoch 113/500\n",
      "579/579 [==============================] - 503s 868ms/step - loss: 2.4621 - accuracy: 0.3489 - val_loss: 3.4527 - val_accuracy: 0.1774\n",
      "Epoch 114/500\n",
      "579/579 [==============================] - 495s 854ms/step - loss: 2.4356 - accuracy: 0.3574 - val_loss: 4.2877 - val_accuracy: 0.2012\n",
      "Epoch 115/500\n",
      "579/579 [==============================] - 493s 852ms/step - loss: 2.4215 - accuracy: 0.3605 - val_loss: 2.8610 - val_accuracy: 0.1789\n",
      "Epoch 116/500\n",
      "579/579 [==============================] - 494s 853ms/step - loss: 2.4240 - accuracy: 0.3588 - val_loss: 4.0208 - val_accuracy: 0.2123\n",
      "Epoch 117/500\n",
      "579/579 [==============================] - 497s 859ms/step - loss: 2.4155 - accuracy: 0.3664 - val_loss: 3.9554 - val_accuracy: 0.2026\n",
      "Epoch 118/500\n",
      "579/579 [==============================] - 542s 936ms/step - loss: 2.4169 - accuracy: 0.3618 - val_loss: 3.3168 - val_accuracy: 0.1963\n",
      "Epoch 119/500\n",
      "579/579 [==============================] - 564s 974ms/step - loss: 2.4000 - accuracy: 0.3653 - val_loss: 2.9154 - val_accuracy: 0.1677\n",
      "Epoch 120/500\n",
      "579/579 [==============================] - 529s 913ms/step - loss: 2.3698 - accuracy: 0.3691 - val_loss: 3.2371 - val_accuracy: 0.2176\n",
      "Epoch 121/500\n",
      "579/579 [==============================] - 551s 951ms/step - loss: 2.3710 - accuracy: 0.3741 - val_loss: 2.5354 - val_accuracy: 0.1934\n",
      "Epoch 122/500\n",
      "579/579 [==============================] - 592s 1s/step - loss: 2.3602 - accuracy: 0.3734 - val_loss: 3.9486 - val_accuracy: 0.1638\n",
      "Epoch 123/500\n",
      "579/579 [==============================] - 629s 1s/step - loss: 2.3543 - accuracy: 0.3743 - val_loss: 3.3408 - val_accuracy: 0.2152\n",
      "Epoch 124/500\n",
      "579/579 [==============================] - 661s 1s/step - loss: 2.3579 - accuracy: 0.3759 - val_loss: 3.5195 - val_accuracy: 0.2147\n",
      "Epoch 125/500\n",
      "579/579 [==============================] - 591s 1s/step - loss: 2.3436 - accuracy: 0.3807 - val_loss: 4.0038 - val_accuracy: 0.2113\n",
      "Epoch 126/500\n",
      "579/579 [==============================] - 608s 1s/step - loss: 2.3280 - accuracy: 0.3820 - val_loss: 4.3108 - val_accuracy: 0.1740\n",
      "Epoch 127/500\n",
      "579/579 [==============================] - 598s 1s/step - loss: 2.3197 - accuracy: 0.3796 - val_loss: 5.6063 - val_accuracy: 0.2249\n",
      "Epoch 128/500\n",
      "579/579 [==============================] - 577s 996ms/step - loss: 2.3265 - accuracy: 0.3810 - val_loss: 4.7401 - val_accuracy: 0.1944\n",
      "Epoch 129/500\n",
      "579/579 [==============================] - 533s 920ms/step - loss: 2.3052 - accuracy: 0.3864 - val_loss: 4.1630 - val_accuracy: 0.2176\n",
      "Epoch 130/500\n",
      "579/579 [==============================] - 632s 1s/step - loss: 2.2929 - accuracy: 0.3900 - val_loss: 3.3154 - val_accuracy: 0.1798\n",
      "Epoch 131/500\n",
      "579/579 [==============================] - 595s 1s/step - loss: 2.2950 - accuracy: 0.3896 - val_loss: 4.0632 - val_accuracy: 0.2099\n",
      "Epoch 132/500\n",
      "579/579 [==============================] - 589s 1s/step - loss: 2.2876 - accuracy: 0.3872 - val_loss: 3.4906 - val_accuracy: 0.2302\n",
      "Epoch 133/500\n",
      "579/579 [==============================] - 562s 970ms/step - loss: 2.2773 - accuracy: 0.3914 - val_loss: 3.3684 - val_accuracy: 0.2099\n",
      "Epoch 134/500\n",
      "579/579 [==============================] - 569s 983ms/step - loss: 2.2729 - accuracy: 0.3930 - val_loss: 3.8581 - val_accuracy: 0.1997\n",
      "Epoch 135/500\n",
      "579/579 [==============================] - 609s 1s/step - loss: 2.2622 - accuracy: 0.3995 - val_loss: 3.3837 - val_accuracy: 0.1997\n",
      "Epoch 136/500\n",
      "579/579 [==============================] - 576s 994ms/step - loss: 2.2449 - accuracy: 0.3988 - val_loss: 4.6231 - val_accuracy: 0.1876\n",
      "Epoch 137/500\n",
      "579/579 [==============================] - 574s 992ms/step - loss: 2.2299 - accuracy: 0.3994 - val_loss: 3.7721 - val_accuracy: 0.1949\n",
      "Epoch 138/500\n",
      "579/579 [==============================] - 541s 935ms/step - loss: 2.2473 - accuracy: 0.4016 - val_loss: 7.9036 - val_accuracy: 0.1546\n",
      "Epoch 139/500\n",
      "579/579 [==============================] - 550s 949ms/step - loss: 2.2200 - accuracy: 0.4070 - val_loss: 4.3698 - val_accuracy: 0.2230\n",
      "Epoch 140/500\n",
      "579/579 [==============================] - 567s 979ms/step - loss: 2.2006 - accuracy: 0.4104 - val_loss: 3.7763 - val_accuracy: 0.2128\n",
      "Epoch 141/500\n",
      "579/579 [==============================] - 567s 979ms/step - loss: 2.2204 - accuracy: 0.4045 - val_loss: 4.6001 - val_accuracy: 0.2429\n",
      "Epoch 142/500\n",
      "579/579 [==============================] - 571s 987ms/step - loss: 2.2066 - accuracy: 0.4048 - val_loss: 4.3423 - val_accuracy: 0.2133\n",
      "Epoch 143/500\n",
      "579/579 [==============================] - 570s 984ms/step - loss: 2.2008 - accuracy: 0.4040 - val_loss: 4.1227 - val_accuracy: 0.2070\n",
      "Epoch 144/500\n",
      "579/579 [==============================] - 585s 1s/step - loss: 2.1945 - accuracy: 0.4090 - val_loss: 3.8858 - val_accuracy: 0.2007\n",
      "Epoch 145/500\n",
      "579/579 [==============================] - 570s 984ms/step - loss: 2.1761 - accuracy: 0.4167 - val_loss: 3.9162 - val_accuracy: 0.2079\n",
      "Epoch 146/500\n",
      "579/579 [==============================] - 642s 1s/step - loss: 2.1798 - accuracy: 0.4151 - val_loss: 3.9636 - val_accuracy: 0.2104\n",
      "Epoch 147/500\n",
      "579/579 [==============================] - 862s 1s/step - loss: 2.1672 - accuracy: 0.4146 - val_loss: 4.5556 - val_accuracy: 0.1808\n",
      "Epoch 148/500\n",
      "579/579 [==============================] - 555s 959ms/step - loss: 2.1571 - accuracy: 0.4168 - val_loss: 4.2300 - val_accuracy: 0.1857\n",
      "Epoch 149/500\n",
      "579/579 [==============================] - 565s 976ms/step - loss: 2.1500 - accuracy: 0.4208 - val_loss: 3.3982 - val_accuracy: 0.2104\n",
      "Epoch 150/500\n",
      "579/579 [==============================] - 1092s 2s/step - loss: 2.1400 - accuracy: 0.4221 - val_loss: 2.7820 - val_accuracy: 0.2283\n",
      "Epoch 151/500\n",
      "579/579 [==============================] - 626s 1s/step - loss: 2.1363 - accuracy: 0.4204 - val_loss: 3.5302 - val_accuracy: 0.1968\n",
      "Epoch 152/500\n",
      "579/579 [==============================] - 550s 951ms/step - loss: 2.1192 - accuracy: 0.4241 - val_loss: 3.1931 - val_accuracy: 0.1905\n",
      "Epoch 153/500\n",
      "579/579 [==============================] - 538s 929ms/step - loss: 2.1225 - accuracy: 0.4244 - val_loss: 3.3169 - val_accuracy: 0.2046\n",
      "Epoch 154/500\n",
      "579/579 [==============================] - 617s 1s/step - loss: 2.1261 - accuracy: 0.4257 - val_loss: 3.1115 - val_accuracy: 0.2317\n",
      "Epoch 155/500\n",
      "579/579 [==============================] - 549s 948ms/step - loss: 2.1212 - accuracy: 0.4207 - val_loss: 4.1793 - val_accuracy: 0.1905\n",
      "Epoch 156/500\n",
      "579/579 [==============================] - 517s 892ms/step - loss: 2.0933 - accuracy: 0.4304 - val_loss: 3.2403 - val_accuracy: 0.1760\n",
      "Epoch 157/500\n",
      "579/579 [==============================] - 519s 897ms/step - loss: 2.0940 - accuracy: 0.4325 - val_loss: 4.6618 - val_accuracy: 0.2327\n",
      "Epoch 158/500\n",
      "579/579 [==============================] - 519s 897ms/step - loss: 2.0846 - accuracy: 0.4342 - val_loss: 3.3854 - val_accuracy: 0.2322\n",
      "Epoch 159/500\n",
      "579/579 [==============================] - 515s 889ms/step - loss: 2.0752 - accuracy: 0.4355 - val_loss: 4.1948 - val_accuracy: 0.2143\n",
      "Epoch 160/500\n",
      "579/579 [==============================] - 520s 898ms/step - loss: 2.0675 - accuracy: 0.4380 - val_loss: 3.9229 - val_accuracy: 0.2036\n",
      "Epoch 161/500\n",
      "579/579 [==============================] - 530s 915ms/step - loss: 2.0587 - accuracy: 0.4349 - val_loss: 4.6569 - val_accuracy: 0.1915\n",
      "Epoch 162/500\n",
      "579/579 [==============================] - 517s 893ms/step - loss: 2.0719 - accuracy: 0.4383 - val_loss: 4.3121 - val_accuracy: 0.2467\n",
      "Epoch 163/500\n",
      "579/579 [==============================] - 521s 900ms/step - loss: 2.0530 - accuracy: 0.4411 - val_loss: 2.4705 - val_accuracy: 0.2225\n",
      "Epoch 164/500\n",
      "579/579 [==============================] - 517s 893ms/step - loss: 2.0525 - accuracy: 0.4401 - val_loss: 5.0214 - val_accuracy: 0.1895\n",
      "Epoch 165/500\n",
      "579/579 [==============================] - 518s 894ms/step - loss: 2.0420 - accuracy: 0.4429 - val_loss: 3.1247 - val_accuracy: 0.1808\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579/579 [==============================] - 513s 886ms/step - loss: 2.0355 - accuracy: 0.4460 - val_loss: 2.9103 - val_accuracy: 0.2254\n",
      "Epoch 167/500\n",
      "579/579 [==============================] - 516s 890ms/step - loss: 2.0342 - accuracy: 0.4404 - val_loss: 4.0882 - val_accuracy: 0.2181\n",
      "Epoch 168/500\n",
      "579/579 [==============================] - 529s 913ms/step - loss: 2.0168 - accuracy: 0.4495 - val_loss: 4.2517 - val_accuracy: 0.1997\n",
      "Epoch 169/500\n",
      "579/579 [==============================] - 507s 876ms/step - loss: 2.0170 - accuracy: 0.4475 - val_loss: 3.6238 - val_accuracy: 0.2269\n",
      "Epoch 170/500\n",
      "579/579 [==============================] - 516s 891ms/step - loss: 2.0047 - accuracy: 0.4497 - val_loss: 3.8643 - val_accuracy: 0.2138\n",
      "Epoch 171/500\n",
      "579/579 [==============================] - 515s 889ms/step - loss: 2.0070 - accuracy: 0.4512 - val_loss: 6.0600 - val_accuracy: 0.2302\n",
      "Epoch 172/500\n",
      "579/579 [==============================] - 516s 891ms/step - loss: 2.0062 - accuracy: 0.4470 - val_loss: 3.3494 - val_accuracy: 0.2065\n",
      "Epoch 173/500\n",
      "579/579 [==============================] - 513s 886ms/step - loss: 1.9955 - accuracy: 0.4520 - val_loss: 2.8887 - val_accuracy: 0.2128\n",
      "Epoch 174/500\n",
      "579/579 [==============================] - 515s 889ms/step - loss: 2.0056 - accuracy: 0.4467 - val_loss: 4.4683 - val_accuracy: 0.1832\n",
      "Epoch 175/500\n",
      "579/579 [==============================] - 528s 912ms/step - loss: 1.9830 - accuracy: 0.4583 - val_loss: 3.0505 - val_accuracy: 0.2079\n",
      "Epoch 176/500\n",
      "579/579 [==============================] - 509s 878ms/step - loss: 1.9651 - accuracy: 0.4581 - val_loss: 4.9523 - val_accuracy: 0.2419\n",
      "Epoch 177/500\n",
      "579/579 [==============================] - 513s 885ms/step - loss: 1.9605 - accuracy: 0.4615 - val_loss: 3.6927 - val_accuracy: 0.1924\n",
      "Epoch 178/500\n",
      "579/579 [==============================] - 510s 880ms/step - loss: 1.9421 - accuracy: 0.4675 - val_loss: 4.2778 - val_accuracy: 0.1769\n",
      "Epoch 179/500\n",
      "579/579 [==============================] - 512s 884ms/step - loss: 1.9249 - accuracy: 0.4729 - val_loss: 4.8051 - val_accuracy: 0.1915\n",
      "Epoch 180/500\n",
      "579/579 [==============================] - 509s 879ms/step - loss: 1.9607 - accuracy: 0.4604 - val_loss: 4.6117 - val_accuracy: 0.1983\n",
      "Epoch 181/500\n",
      "579/579 [==============================] - 513s 886ms/step - loss: 1.9406 - accuracy: 0.4653 - val_loss: 4.1891 - val_accuracy: 0.2176\n",
      "Epoch 182/500\n",
      "579/579 [==============================] - 513s 885ms/step - loss: 1.9417 - accuracy: 0.4646 - val_loss: 3.7477 - val_accuracy: 0.1609\n",
      "Epoch 183/500\n",
      "579/579 [==============================] - 511s 882ms/step - loss: 1.9244 - accuracy: 0.4688 - val_loss: 4.0646 - val_accuracy: 0.2317\n",
      "Epoch 184/500\n",
      "579/579 [==============================] - 524s 906ms/step - loss: 1.9049 - accuracy: 0.4780 - val_loss: 4.9165 - val_accuracy: 0.2026\n",
      "Epoch 185/500\n",
      "579/579 [==============================] - 511s 882ms/step - loss: 1.9230 - accuracy: 0.4645 - val_loss: 3.1943 - val_accuracy: 0.2036\n",
      "Epoch 186/500\n",
      "579/579 [==============================] - 510s 881ms/step - loss: 1.9245 - accuracy: 0.4633 - val_loss: 3.9184 - val_accuracy: 0.2341\n",
      "Epoch 187/500\n",
      "579/579 [==============================] - 506s 874ms/step - loss: 1.9047 - accuracy: 0.4748 - val_loss: 5.3978 - val_accuracy: 0.2007\n",
      "Epoch 188/500\n",
      "579/579 [==============================] - 513s 887ms/step - loss: 1.9109 - accuracy: 0.4735 - val_loss: 5.7306 - val_accuracy: 0.2133\n",
      "Epoch 189/500\n",
      "579/579 [==============================] - 512s 884ms/step - loss: 1.9017 - accuracy: 0.4762 - val_loss: 4.7939 - val_accuracy: 0.1779\n",
      "Epoch 190/500\n",
      "579/579 [==============================] - 507s 876ms/step - loss: 1.8895 - accuracy: 0.4777 - val_loss: 6.3552 - val_accuracy: 0.2050\n",
      "Epoch 191/500\n",
      "579/579 [==============================] - 526s 908ms/step - loss: 1.8722 - accuracy: 0.4872 - val_loss: 4.6024 - val_accuracy: 0.2118\n",
      "Epoch 192/500\n",
      "579/579 [==============================] - 514s 887ms/step - loss: 1.8767 - accuracy: 0.4808 - val_loss: 3.9168 - val_accuracy: 0.1876\n",
      "Epoch 193/500\n",
      "579/579 [==============================] - 541s 934ms/step - loss: 1.8740 - accuracy: 0.4829 - val_loss: 5.4721 - val_accuracy: 0.2070\n",
      "Epoch 194/500\n",
      "579/579 [==============================] - 507s 876ms/step - loss: 1.8683 - accuracy: 0.4869 - val_loss: 2.4614 - val_accuracy: 0.2317\n",
      "Epoch 195/500\n",
      "579/579 [==============================] - 513s 885ms/step - loss: 1.8700 - accuracy: 0.4826 - val_loss: 3.7757 - val_accuracy: 0.2176\n",
      "Epoch 196/500\n",
      "579/579 [==============================] - 513s 887ms/step - loss: 1.8659 - accuracy: 0.4814 - val_loss: 6.0216 - val_accuracy: 0.2298\n",
      "Epoch 197/500\n",
      "579/579 [==============================] - 510s 880ms/step - loss: 1.8416 - accuracy: 0.4903 - val_loss: 3.8604 - val_accuracy: 0.2385\n",
      "Epoch 198/500\n",
      "579/579 [==============================] - 513s 885ms/step - loss: 1.8427 - accuracy: 0.4865 - val_loss: 2.9897 - val_accuracy: 0.2239\n",
      "Epoch 199/500\n",
      "579/579 [==============================] - 524s 905ms/step - loss: 1.8395 - accuracy: 0.4876 - val_loss: 4.3918 - val_accuracy: 0.2046\n",
      "Epoch 200/500\n",
      "579/579 [==============================] - 508s 877ms/step - loss: 1.8353 - accuracy: 0.4900 - val_loss: 5.8775 - val_accuracy: 0.2215\n",
      "Epoch 201/500\n",
      "579/579 [==============================] - 501s 866ms/step - loss: 1.8366 - accuracy: 0.4922 - val_loss: 2.9080 - val_accuracy: 0.2225\n",
      "Epoch 202/500\n",
      "579/579 [==============================] - 509s 880ms/step - loss: 1.8313 - accuracy: 0.4881 - val_loss: 2.8972 - val_accuracy: 0.2269\n",
      "Epoch 203/500\n",
      "579/579 [==============================] - 507s 876ms/step - loss: 1.8128 - accuracy: 0.4964 - val_loss: 3.4729 - val_accuracy: 0.2007\n",
      "Epoch 204/500\n",
      "579/579 [==============================] - 513s 886ms/step - loss: 1.8277 - accuracy: 0.4906 - val_loss: 5.7205 - val_accuracy: 0.1924\n",
      "Epoch 205/500\n",
      "579/579 [==============================] - 512s 884ms/step - loss: 1.8104 - accuracy: 0.4997 - val_loss: 5.0833 - val_accuracy: 0.2375\n",
      "Epoch 206/500\n",
      "579/579 [==============================] - 510s 881ms/step - loss: 1.7967 - accuracy: 0.4975 - val_loss: 3.0614 - val_accuracy: 0.2123\n",
      "Epoch 207/500\n",
      "579/579 [==============================] - 509s 879ms/step - loss: 1.7888 - accuracy: 0.4998 - val_loss: 6.1094 - val_accuracy: 0.2157\n",
      "Epoch 208/500\n",
      "579/579 [==============================] - 505s 872ms/step - loss: 1.7929 - accuracy: 0.5019 - val_loss: 7.2566 - val_accuracy: 0.2453\n",
      "Epoch 209/500\n",
      "579/579 [==============================] - 523s 904ms/step - loss: 1.7931 - accuracy: 0.4971 - val_loss: 4.5172 - val_accuracy: 0.2196\n",
      "Epoch 210/500\n",
      "579/579 [==============================] - 507s 875ms/step - loss: 1.7802 - accuracy: 0.5066 - val_loss: 4.0792 - val_accuracy: 0.2259\n",
      "Epoch 211/500\n",
      "579/579 [==============================] - 507s 875ms/step - loss: 1.8016 - accuracy: 0.4959 - val_loss: 3.8587 - val_accuracy: 0.2332\n",
      "Epoch 212/500\n",
      "579/579 [==============================] - 512s 884ms/step - loss: 1.7923 - accuracy: 0.4992 - val_loss: 3.0397 - val_accuracy: 0.2026\n",
      "Epoch 213/500\n",
      "579/579 [==============================] - 515s 890ms/step - loss: 1.7678 - accuracy: 0.5050 - val_loss: 5.8004 - val_accuracy: 0.2118\n",
      "Epoch 214/500\n",
      "579/579 [==============================] - 512s 884ms/step - loss: 1.7517 - accuracy: 0.5086 - val_loss: 3.9102 - val_accuracy: 0.2220\n",
      "Epoch 215/500\n",
      "579/579 [==============================] - 519s 897ms/step - loss: 1.7588 - accuracy: 0.5060 - val_loss: 5.2072 - val_accuracy: 0.2016\n",
      "Epoch 216/500\n",
      "579/579 [==============================] - 519s 897ms/step - loss: 1.7586 - accuracy: 0.5057 - val_loss: 3.5890 - val_accuracy: 0.2206\n",
      "Epoch 217/500\n",
      "579/579 [==============================] - 516s 891ms/step - loss: 1.7639 - accuracy: 0.5040 - val_loss: 6.1472 - val_accuracy: 0.1692\n",
      "Epoch 218/500\n",
      "579/579 [==============================] - 525s 906ms/step - loss: 1.7381 - accuracy: 0.5159 - val_loss: 4.4743 - val_accuracy: 0.2283\n",
      "Epoch 219/500\n",
      "579/579 [==============================] - 514s 887ms/step - loss: 1.7468 - accuracy: 0.5098 - val_loss: 3.5847 - val_accuracy: 0.2298\n",
      "Epoch 220/500\n",
      "579/579 [==============================] - 517s 893ms/step - loss: 1.7296 - accuracy: 0.5117 - val_loss: 4.6620 - val_accuracy: 0.1823\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579/579 [==============================] - 517s 893ms/step - loss: 1.7376 - accuracy: 0.5130 - val_loss: 3.3839 - val_accuracy: 0.2424\n",
      "Epoch 222/500\n",
      "579/579 [==============================] - 515s 890ms/step - loss: 1.7279 - accuracy: 0.5147 - val_loss: 4.4179 - val_accuracy: 0.2031\n",
      "Epoch 223/500\n",
      "579/579 [==============================] - 517s 893ms/step - loss: 1.7236 - accuracy: 0.5185 - val_loss: 3.9742 - val_accuracy: 0.2361\n",
      "Epoch 224/500\n",
      "579/579 [==============================] - 515s 889ms/step - loss: 1.7226 - accuracy: 0.5216 - val_loss: 5.5827 - val_accuracy: 0.1983\n",
      "Epoch 225/500\n",
      "579/579 [==============================] - 516s 891ms/step - loss: 1.6912 - accuracy: 0.5252 - val_loss: 4.9804 - val_accuracy: 0.2070\n",
      "Epoch 226/500\n",
      "579/579 [==============================] - 529s 913ms/step - loss: 1.7035 - accuracy: 0.5200 - val_loss: 4.1919 - val_accuracy: 0.2351\n",
      "Epoch 227/500\n",
      "579/579 [==============================] - 604s 1s/step - loss: 1.7031 - accuracy: 0.5217 - val_loss: 4.1044 - val_accuracy: 0.2007\n",
      "Epoch 228/500\n",
      "579/579 [==============================] - 558s 964ms/step - loss: 1.7142 - accuracy: 0.5160 - val_loss: 3.4674 - val_accuracy: 0.2448\n",
      "Epoch 229/500\n",
      "579/579 [==============================] - 561s 968ms/step - loss: 1.7074 - accuracy: 0.5235 - val_loss: 5.5310 - val_accuracy: 0.2239\n",
      "Epoch 230/500\n",
      "579/579 [==============================] - 563s 972ms/step - loss: 1.6900 - accuracy: 0.5257 - val_loss: 6.1859 - val_accuracy: 0.2046\n",
      "Epoch 231/500\n",
      "579/579 [==============================] - 529s 914ms/step - loss: 1.6866 - accuracy: 0.5255 - val_loss: 6.5643 - val_accuracy: 0.2084\n",
      "Epoch 232/500\n",
      "579/579 [==============================] - 569s 984ms/step - loss: 1.6835 - accuracy: 0.5251 - val_loss: 4.3507 - val_accuracy: 0.2206\n",
      "Epoch 233/500\n",
      "579/579 [==============================] - 538s 930ms/step - loss: 1.6879 - accuracy: 0.5218 - val_loss: 3.3762 - val_accuracy: 0.2365\n",
      "Epoch 234/500\n",
      "579/579 [==============================] - 535s 924ms/step - loss: 1.6935 - accuracy: 0.5225 - val_loss: 4.2231 - val_accuracy: 0.1997\n",
      "Epoch 235/500\n",
      "579/579 [==============================] - 520s 899ms/step - loss: 1.6834 - accuracy: 0.5251 - val_loss: 6.2764 - val_accuracy: 0.2143\n",
      "Epoch 236/500\n",
      "579/579 [==============================] - 521s 900ms/step - loss: 1.6770 - accuracy: 0.5232 - val_loss: 3.6915 - val_accuracy: 0.2259\n",
      "Epoch 237/500\n",
      "579/579 [==============================] - 563s 973ms/step - loss: 1.6731 - accuracy: 0.5306 - val_loss: 4.1596 - val_accuracy: 0.2176\n",
      "Epoch 238/500\n",
      "579/579 [==============================] - 525s 906ms/step - loss: 1.6659 - accuracy: 0.5294 - val_loss: 3.3915 - val_accuracy: 0.2244\n",
      "Epoch 239/500\n",
      "579/579 [==============================] - 606s 1s/step - loss: 1.6511 - accuracy: 0.5347 - val_loss: 3.4283 - val_accuracy: 0.2152\n",
      "Epoch 240/500\n",
      "579/579 [==============================] - 547s 945ms/step - loss: 1.6520 - accuracy: 0.5329 - val_loss: 4.0822 - val_accuracy: 0.2269\n",
      "Epoch 241/500\n",
      "579/579 [==============================] - 540s 932ms/step - loss: 1.6396 - accuracy: 0.5378 - val_loss: 3.9329 - val_accuracy: 0.2298\n",
      "Epoch 242/500\n",
      "190/579 [========>.....................] - ETA: 5:52 - loss: 1.6153 - accuracy: 0.5442"
     ]
    }
   ],
   "source": [
    "model.fit_generator(training_data, epochs=500, validation_data = test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
